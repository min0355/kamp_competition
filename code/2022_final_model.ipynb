{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a794dc3",
   "metadata": {},
   "source": [
    "#### 파일 1 개만 제출 가능하여 여러 개의 주피터 작업 본을 합친 양식이라 중간 전개가 약간 어색 할 수 있습니다.  \n",
    "#### 끝에는 py 파일도 코드를 넣었으니 참고 부탁 드립니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가로로 넓게 쓰기\n",
    "from IPython.core.display import display, HTML  \n",
    "display(HTML(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10503526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# ML Library\n",
    "import pandas_profiling \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV, GroupKFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, precision_score, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek # 오버 샘플링 성능 비교용 \n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from adamp import AdamP\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import GRU, Dropout, Dense, Conv1D\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# importing plotly and cufflinks in offline mode\n",
    "# import cufflinks as cf\n",
    "# import plotly.offline as pyo\n",
    "# cf.go_offline()\n",
    "# cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "# pyo.init_notebook_mode()\n",
    "\n",
    "# TPOT : Automatic ML library that automatically enables feature selection and Hyperparameter learning based on multiple machine learning models \n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f69992",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kym/ML/input/kamp/대회 과제\"\n",
    "os.chdir(path)\n",
    "\n",
    "df = pd.read_csv('melting_tank.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a990a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704281a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.profile_report()\n",
    "# profile = df.profile_report(title='Competition_Pandas Profiling Report')\n",
    "# profile.to_file(output_file=\"Competition data profiling.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a073297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MELT_TEMP'] = (df['MELT_TEMP'] / 10) # 용해온도, 교반속도 데이터는 소수점 1 자리 생략 \n",
    "df['MOTORSPEED'] = (df['MOTORSPEED'] / 10)\n",
    "\n",
    "result_mapping = {\n",
    "    \"OK\": 1,\n",
    "    \"NG\": 0\n",
    "}\n",
    "\n",
    "df.loc[:, \"TAG\"] = df.TAG.map(result_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "df_corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(df_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.heatmap(df_corr, ax=ax,\n",
    "           square=True, center=0, linewidth=1,\n",
    "           cmap=sns.diverging_palette(240, 10, as_cmap=True),\n",
    "           cbar_kws={'shrink': .82},\n",
    "           mask=mask,\n",
    "           annot=True,\n",
    "           annot_kws={'size':7}\n",
    "           )\n",
    "ax.set_title(f'Correlation', loc='left', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ad15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 수분 함유량 (INSP) 가 3.21 ~ 3.23 은 불량이 극히 적다. (높을수록 정상이 많음.)\n",
    "# df[['INSP', 'TAG']].groupby(['INSP'], as_index=True).mean().iplot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STD_DT'] = df['STD_DT'].apply(lambda x: pd.to_datetime(str(x), format='%Y-%m-%d %H:%M', errors='coerce'))\n",
    "df.set_index('STD_DT', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8de73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(\"=============================================\")\n",
    "    sns.distplot(df[i])\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 용량 문제로 주석 처리 \n",
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.scatter(df, x='MOTORSPEED', y='INSP', marginal_y='histogram', marginal_x='histogram')\n",
    "# fig.show()\n",
    "# fig = px.scatter(df, x='MELT_WEIGHT', y='INSP', marginal_y='histogram', marginal_x='histogram')\n",
    "# fig.show()\n",
    "# fig = px.scatter(df, x='MELT_TEMP', y='INSP', marginal_y='histogram', marginal_x='histogram')\n",
    "# fig.show()\n",
    "# fig = px.scatter(df, x='INSP', y='TAG', marginal_y='histogram', marginal_x='histogram')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중량의 경우 너무 과한 값은 삭제 \n",
    "sns.boxplot(x='MELT_WEIGHT', orient = \"v\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faebb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 관측 어려운 feature 는 제외 \n",
    "df.drop(['INSP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['MELT_WEIGHT', 'TAG']].plot(kind='line', figsize=(20,6), linewidth=2, fontsize=20, colormap='winter')\n",
    "plt.xlabel('time', fontsize=15)\n",
    "plt.ylabel('MinMax label', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질량 전 처리 : 조건은 직전 값과 100이상 차이 나는 경우 시계열상 다다음 스텝(30스텝까지)의 무게와 비교해서 증감 비율 맞춰서 보정하는 형태\n",
    "Dlength = df.shape[0]\n",
    "s_step = 30\n",
    "\n",
    "for k in df.NUM:\n",
    "    if k >= 1:\n",
    "        if abs(df.MELT_WEIGHT[k] - df.MELT_WEIGHT[k-1]) > 100:\n",
    "            \n",
    "            for s in range(s_step):\n",
    "                if abs(df.MELT_WEIGHT[k-1] - df.MELT_WEIGHT[k+s]) < 500: \n",
    "                    step = round(abs(df.MELT_WEIGHT[k-1] - df.MELT_WEIGHT[k+s]) / (s+1))\n",
    "                    \n",
    "                    if df.MELT_WEIGHT[k-1] > df.MELT_WEIGHT[k+s]:\n",
    "                        df.MELT_WEIGHT[k] = df.MELT_WEIGHT[k-1] - step\n",
    "                    \n",
    "                    else:\n",
    "                        df.MELT_WEIGHT[k] = df.MELT_WEIGHT[k-1] + step\n",
    "                    break\n",
    "\n",
    "df.to_csv('/home/kym/ML/input/kamp/대회 과제/melting_tank_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kym/ML/input/kamp/대회 과제\"\n",
    "os.chdir(path)\n",
    "\n",
    "df = pd.read_csv('melting_tank_mod.csv', encoding='cp949')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수정 이 후 \n",
    "df[['MELT_WEIGHT', 'TAG']].plot(kind='line', figsize=(20,6), linewidth=2, fontsize=20, colormap='winter')\n",
    "plt.xlabel('time', fontsize=15)\n",
    "plt.ylabel('MinMax label', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ff6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STD_DT'] = df['STD_DT'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30873783",
   "metadata": {},
   "source": [
    "온도와 모터 스피드 간 높은 상관성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c29bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처별 점수\n",
    "from functools import partial\n",
    "from scipy import optimize\n",
    "\n",
    "class OptimizeAUC:\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "        \n",
    "    def _auc(self, coef, X, y):\n",
    "        '''\n",
    "        :params coef : weight list\n",
    "        '''\n",
    "        x_coef = X * coef\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        auc_score = metrics.roc_auc_score(y, predictions)\n",
    "        \n",
    "        return -1.0 * auc_score\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._auc, X=X, y=y)\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size=1)\n",
    "        self.coef_ = optimize.fmin(loss_partial, initial_coef, disp=True)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['STD_DT', 'NUM', 'TAG'], axis=1)\n",
    "y = df['TAG']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104de91d",
   "metadata": {},
   "outputs": [],
   "source": [
    " 랜덤 포레스트, light GBM, XGBoost, DL, KNN => ENSEMBLE\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.5,\n",
    "    stratify=y,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "lgb = lgb.LGBMClassifier(num_leaves=31, \n",
    "                         objective='binary',\n",
    "                         num_iterations=200,\n",
    "                         max_depth=5\n",
    "                        )\n",
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "xgb = xgb.XGBClassifier(random_state=42,\n",
    "                       booster='gbtree',\n",
    "                       n_jobs=-1,\n",
    "                       eval_metric='error',\n",
    "                       learning_rate=0.1,\n",
    "                       n_estimators=200,\n",
    "                       max_depth=5,\n",
    "                       reg_lambda=2\n",
    "                       )\n",
    "\n",
    "lgb.fit(x_train_scaled, y_train)\n",
    "rf.fit(x_train_scaled, y_train)\n",
    "knn.fit(x_train_scaled, y_train)\n",
    "xgb.fit(x_train_scaled, y_train)\n",
    "\n",
    "pred_lgb = lgb.predict_proba(x_test_scaled)[:, 1]\n",
    "pred_rf = rf.predict_proba(x_test_scaled)[:, 1]\n",
    "pred_knn = knn.predict_proba(x_test_scaled)[:, 1]\n",
    "pred_xgb = xgb.predict_proba(x_test_scaled)[:, 1]\n",
    "avg_pred = (pred_xgb + pred_rf + pred_knn + pred_xgb) / 4\n",
    "\n",
    "test_preds = np.column_stack((\n",
    "            pred_lgb,\n",
    "            pred_rf,\n",
    "            pred_knn,\n",
    "            pred_xgb,\n",
    "            avg_pred\n",
    "))\n",
    "\n",
    "aucs_test = []\n",
    "\n",
    "for i in range(test_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(y_test, test_preds[:, i])\n",
    "    aucs_test.append(auc)\n",
    "    \n",
    "print(f\"테스트 셋: LightGBM AUC = {aucs_test[0]}\")\n",
    "print(f\"테스트 셋: RandomForest AUC = {aucs_test[1]}\")\n",
    "print(f\"테스트 셋: KNN AUC = {aucs_test[2]}\")\n",
    "print(f\"테스트 셋: XGBoost AUC = {aucs_test[3]}\")\n",
    "print(f\"테스트 셋: Average Pred AUC = {aucs_test[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4974a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.fit(x_test_scaled, y_test)\n",
    "rf.fit(x_test_scaled, y_test)\n",
    "knn.fit(x_test_scaled, y_test)\n",
    "xgb.fit(x_test_scaled, y_test)\n",
    "\n",
    "pred_lgb = lgb.predict_proba(x_train_scaled)[:, 1]\n",
    "pred_rf = rf.predict_proba(x_train_scaled)[:, 1]\n",
    "pred_knn = knn.predict_proba(x_train_scaled)[:, 1]\n",
    "pred_xgb = xgb.predict_proba(x_train_scaled)[:, 1]\n",
    "avg_pred = (pred_xgb + pred_rf + pred_knn + pred_xgb) / 4\n",
    "\n",
    "train_preds = np.column_stack((\n",
    "            pred_lgb,\n",
    "            pred_rf,\n",
    "            pred_knn,\n",
    "            pred_xgb,\n",
    "            avg_pred\n",
    "))\n",
    "\n",
    "aucs_train = []\n",
    "\n",
    "for i in range(train_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(y_train, train_preds[:, i])\n",
    "    aucs_train.append(auc)\n",
    "    \n",
    "print(f\"테스트 셋: LightGBM AUC = {aucs_train[0]}\")\n",
    "print(f\"테스트 셋: RandomForest AUC = {aucs_train[1]}\")\n",
    "print(f\"테스트 셋: KNN AUC = {aucs_train[2]}\")\n",
    "print(f\"테스트 셋: XGBoost AUC = {aucs_train[3]}\")\n",
    "print(f\"테스트 셋: Average Pred AUC = {aucs_train[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = OptimizeAUC()\n",
    "opt.fit(train_preds[:, :-1], y_train)\n",
    "opt_preds_test = opt.predict(test_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(y_test, opt_preds_test)\n",
    "\n",
    "print(f\"Optimized AUC, Test set = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")\n",
    "\n",
    "opt = OptimizeAUC()\n",
    "opt.fit(test_preds[:, :-1], y_test)\n",
    "opt_preds_train = opt.predict(train_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(y_train, opt_preds_train)\n",
    "\n",
    "print(f\"Optimized AUC, Train set = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70993e",
   "metadata": {},
   "source": [
    "* 피처 1 개 (온도) : 0.774 (optimized auc 0.78)  \n",
    "* 피처 1 개 (모터 속도) : 0.73 (optimized auc 0.736)  \n",
    "* 피처 2 개 (온도, 모터 속도) : 0.77 (optimized auc 0.78)  \n",
    "* 피처 3 개 (온도, 모터 속도, 중량): 0.79 (optimized auc 0.80)  \n",
    "* 피처 4 개 (온도, 모터 속도, 중량, insp) : 0.79 (optimized auc 0.80)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831bec56",
   "metadata": {},
   "source": [
    "온도, 모터 회전 수까지만 학습에 사용 : Metric 뿐만 아니라 데이터 수집 측면에서 INSP 는 불리하고 중량은 영향도가 미미하기 때문임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b08fd9b",
   "metadata": {},
   "source": [
    "feature 확장 가능성 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8201781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    df.loc[:,  'year'] = df['STD_DT'].dt.year\n",
    "    df.loc[:, 'weekofyear'] = df['STD_DT'].dt.weekofyear\n",
    "    df.loc[:, 'month'] = df['STD_DT'].dt.month\n",
    "    df.loc[:, 'dayofweek'] = df['STD_DT'].dt.dayofweek\n",
    "    df.loc[:, 'weekend'] = (df['STD_DT'].dt.weekday >=5).astype(int)\n",
    "#     df.loc[:, 'hour'] = df['STD_DT'].dt.hour\n",
    "#     df.loc[:, 'min'] = df['STD_DT'].dt.mimute\n",
    "    \n",
    "    aggs = {}\n",
    "#     aggs['month'] = ['nunique', 'mean']\n",
    "#     aggs['weekofyear'] = ['mean']\n",
    "    aggs['MELT_TEMP'] = ['max', 'min', 'mean']\n",
    "    aggs['MOTORSPEED'] = ['max', 'min', 'mean']\n",
    "    aggs['MELT_WEIGHT'] = ['max', 'min', 'mean']\n",
    "#     aggs['NUM'] = ['size']\n",
    "#     aggs['NUM'] = ['nunique']\n",
    "    \n",
    "    agg_df = df.groupby('NUM').agg(aggs)\n",
    "    agg_df = agg_df.reset_index()\n",
    "    \n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = generate_features(df)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df1], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d91752",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548dddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "df_corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(df_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.heatmap(df_corr, ax=ax,\n",
    "           square=True, center=0, linewidth=1,\n",
    "           cmap=sns.diverging_palette(240, 10, as_cmap=True),\n",
    "           cbar_kws={'shrink': .82},\n",
    "           mask=mask,\n",
    "           annot=True,\n",
    "           annot_kws={'size':7}\n",
    "           )\n",
    "ax.set_title(f'Correlation', loc='left', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee300c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77982825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    f for f in df.columns if f not in ('STD_DT', 'NUM', 'TAG', 'year', 'weekofyear', 'month', 'dayofweek', 'weekend', ('NUM', ''))\n",
    "]\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "X = df.drop(['STD_DT', 'NUM', ('NUM', ''), 'TAG'], axis=1)\n",
    "y = df['TAG'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d85377",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "rfe = RFE(\n",
    "    estimator=rf,\n",
    "    n_features_to_select=5)\n",
    "\n",
    "rfe.fit(X, y)\n",
    "\n",
    "X_transformed = rfe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt_temp, weekofyear, dayofweek\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc018ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc8d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    df['STD_DT'] = df['STD_DT'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "    df.loc[:, 'weekofyear'] = df['STD_DT'].dt.weekofyear\n",
    "    df.loc[:, 'dayofweek'] = df['STD_DT'].dt.dayofweek\n",
    "    df.loc[:, 'weekend'] = (df['STD_DT'].dt.weekday >=5).astype(int)\n",
    "#     df.loc[:, 'hour'] = df['STD_DT'].dt.hour\n",
    "#     df.loc[:, 'min'] = df['STD_DT'].dt.mimute\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kym/ML/input/kamp/대회 과제\"\n",
    "os.chdir(path)\n",
    "\n",
    "df = pd.read_csv('melting_tank_mod.csv', encoding='cp949')\n",
    "\n",
    "df = generate_features(df)\n",
    "feature = [\n",
    "    f for f in df.columns if f in (\"STD_DT\", \"MELT_TEMP\", \"MOTORSPEED\", \"MELT_WEIGHT\", \"weekofyear\", \"dayofweek\", \"weekend\", \"TAG\")\n",
    "]\n",
    "\n",
    "df = df[feature]\n",
    "\n",
    "df.to_csv('/home/kym/ML/input/kamp/대회 과제/melting_tank_final.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba881264",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_features = [\n",
    "    f for f in df.columns if f in ('MELT_TEMP', 'MOTORSPEED', 'MELT_WEIGHT')\n",
    "]\n",
    "df[scaler_features] = scaler.fit_transform(df[scaler_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['STD_DT', 'TAG'], axis=1)\n",
    "y = pd.DataFrame(df['TAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 정상, 0 불량 (가이드 북 기준, 본래는 유저가 관심 있는 것을 보통 1 로 사용)\n",
    "print(\"정상 개수 : {} ({:.2f} %)\".format(y.TAG.value_counts()[1], y.TAG.value_counts(normalize=True)[1]))\n",
    "print(\"비 정상 개수: {} ({:.2f} %)\".format(y.TAG.value_counts()[0], y.TAG.value_counts(normalize=True)[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    plt.title(col)\n",
    "    x = np.linspace(0, X.shape[0])\n",
    "    ax.plot(X[col])\n",
    "    ax.plot(y['TAG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bc40f",
   "metadata": {},
   "source": [
    "근무일과 같은 시간에 주기성을 띄기 보단 그냥 특정 시점에 집중적으로 불량이 몰려 있음.  \n",
    "따라서, 평일, 주 차 등의 근무 연관성은 낮다고 봐야 함.  \n",
    "(근무자가 불량이거나 투입 중량 시스템 오류 등 데이터에 명시되지 않은 다른 원인 추정 가능)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af7057",
   "metadata": {},
   "source": [
    "불량 구간 확대 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad112d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불량 발생 지점 확대, 그림이 잘 보이게 하기 위해 첫 번째는 라벨 없이 데이터만 도시 \n",
    "eventrow = 200000\n",
    "\n",
    "minx = eventrow - 50\n",
    "maxx = eventrow + 50\n",
    "\n",
    "for col in X.columns:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    plt.title(col)\n",
    "    \n",
    "    x = np.linspace(minx, maxx)\n",
    "    ax.plot(X[col][minx : maxx])\n",
    "#     ax.plot(y['TAG'][minx : maxx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c45d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불량 발생 지점 확대, 라벨과 비교 : 시간적인 feature (작업 시간, 출 퇴근이나 작업자 성향을 간접 파악) 들과 전혀 관계 없으며 , \n",
    "# 재료 질량과도 거의 상관 없음. (LInear 한 감소에서 주기적 라벨링 관찰) \n",
    "# 온도와 모터 스피드 변화에 따라 광범위한 일정 영역 대에서 집중 발생함을 알 수 있음. \n",
    "\n",
    "eventrow = 200000\n",
    "\n",
    "minx = eventrow - 50\n",
    "maxx = eventrow + 50\n",
    "\n",
    "for col in X.columns:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    plt.title(col)\n",
    "    \n",
    "    x = np.linspace(minx, maxx)\n",
    "    ax.plot(X[col][minx : maxx])\n",
    "    ax.plot(y['TAG'][minx : maxx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d168e1c",
   "metadata": {},
   "source": [
    "정상 구간 확대 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불량 발생 지점 확대, 그림이 잘 보이게 하기 위해 첫 번째는 라벨 없이 데이터만 도시 \n",
    "eventrow = 100000\n",
    "\n",
    "minx = eventrow - 50\n",
    "maxx = eventrow + 50\n",
    "\n",
    "for col in X.columns:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    plt.title(col)\n",
    "    \n",
    "    x = np.linspace(minx, maxx)\n",
    "    ax.plot(X[col][minx : maxx])\n",
    "#     ax.plot(y['TAG'][minx : maxx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbaf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상 구간 지점 확대, 라벨과 비교 : 시간적인 feature (작업 시간, 출 퇴근이나 작업자 성향을 간접 파악) 들과 전혀 관계 없으며 , \n",
    "# 재료 질량과도 거의 상관 없음. (LInear 한 감소에서 주기적 라벨링 관찰) \n",
    "# 온도와 모터 스피드 변화에 따라 광범위한 일정 영역 대에서 집중 발생함을 알 수 있음. \n",
    "\n",
    "eventrow = 100000\n",
    "\n",
    "minx = eventrow - 50\n",
    "maxx = eventrow + 50\n",
    "\n",
    "for col in X.columns:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    plt.title(col)\n",
    "    \n",
    "    x = np.linspace(minx, maxx)\n",
    "    ax.plot(X[col][minx : maxx])\n",
    "    ax.plot(y['TAG'][minx : maxx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f221844",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['TAG'] = y['TAG']\n",
    "\n",
    "normal = X[X['TAG'] == 1]\n",
    "anomaly = X[X['TAG'] == 0]\n",
    "\n",
    "print(normal.shape)\n",
    "print(anomaly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상과 비 정상의 통계 정보 : 날짜 관련은 TAG 와 상관 없음을 알 수 있다. \n",
    "normal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b76698",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objs as go\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIT 업로드 용량 문제로 주석 처리 : 온도 - 모터 속도 - 중량 순으로 연관도를 보임. \n",
    "\n",
    "# features = ['MELT_TEMP', 'MOTORSPEED', 'MELT_WEIGHT']\n",
    "\n",
    "# for col in features:\n",
    "#     trace0 = go.Box(\n",
    "#                     y=normal[col],\n",
    "#                     name=\"normal state\",\n",
    "#                     marker=dict(\n",
    "#                     color = 'rgb(12, 12, 140)',\n",
    "#                     )\n",
    "#     )\n",
    "    \n",
    "#     trace1 = go.Box(\n",
    "#                     y=anomaly[col],\n",
    "#                     name=\"anomaly state\",\n",
    "#                     marker=dict(\n",
    "#                     color = 'rgb(12, 128, 128)',\n",
    "#                     )\n",
    "#     )\n",
    "#     data = [trace0, trace1]\n",
    "#     iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64ddd3",
   "metadata": {},
   "source": [
    "모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f93d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kym/ML/input/kamp/대회 과제\"\n",
    "os.chdir(path)\n",
    "model_path = path\n",
    "\n",
    "df = pd.read_csv('melting_tank_mod.csv', encoding='cp949')\n",
    "\n",
    "feature = [\n",
    "    f for f in df.columns if f not in (\"NUM\")\n",
    "]\n",
    "\n",
    "df = df[feature]\n",
    "df['STD_DT'] = df['STD_DT'].apply(lambda x: pd.to_datetime(str(x), format='%Y-%m-%d %H:%M:%S', errors='coerce'))\n",
    "df.set_index('STD_DT', inplace=True)\n",
    "\n",
    "df.to_csv('/home/kym/ML/input/kamp/대회 과제/melting_tank_final.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe11584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준 편차가 큰 feature 인 재료의 질량은 관찰 그래프를 통해 극히 영향도가 미미한 것을 알았기에 제외하고, 탱크 온도와 모터 속도만으로 학습함. \n",
    "df.describe().T.style.bar(subset=['mean'], color='#205ff2').background_gradient(subset=['std'], cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60271633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 83 만여개를 모두 사용하여 학습할 경우 real time detection 이 전부 정상으로 나오는 문제가 발생함.\n",
    "# 따라서, 정상 구간 부분을 버리고 OK / NG 가 모두 존재하는 부분만 학습을 진행함. \n",
    "\n",
    "start_point = 189000\n",
    "end_point = 580000\n",
    "\n",
    "df = df.iloc[start_point:end_point, :]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78187483",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['MELT_WEIGHT', 'TAG'], axis=1)\n",
    "y = df['TAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16124ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteto = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'), random_state=42)\n",
    "x_train_over, y_train_over = smoteto.fit_resample(x_train, y_train)\n",
    "\n",
    "print(\"SMOTETomek 적용 전 학습용 피처 / 라벨 세트: \", x_train.shape, y_train.shape)\n",
    "print(\"SMOTETomek 적용 후 학습용 피처 / 라벨 세트: \", x_train_over.shape, y_train_over.shape)\n",
    "print(\"SMOTETomek 적용 후 라벨 값 분포: \\n\", pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c487e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, label, window_size):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(len(df) - window_size):\n",
    "        feature_list.append(np.array(df.iloc[i : i + window_size]))\n",
    "        label_list.append(np.array(label.iloc[i + window_size]))\n",
    "        \n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "x_train_over = pd.DataFrame(x_train_over, columns=['MELT_TEMP', 'MOTORSPEED'])\n",
    "y_train_over = pd.DataFrame(y_train_over, columns=['TAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94815cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window size = 10\n",
    "train_feature, train_label = process_data(x_train_over, y_train_over, 10)\n",
    "train_feature.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.DataFrame(x_test, columns=['MELT_TEMP', 'MOTORSPEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature, test_label = process_data(x_test, y_test, 10)\n",
    "test_feature.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.3)\n",
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1bb82",
   "metadata": {},
   "source": [
    "모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1246f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(64,\n",
    "              input_shape=(train_feature.shape[1], train_feature.shape[2]),\n",
    "              activation='tanh',\n",
    "              return_sequences=True)\n",
    "         )\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(GRU(16,\n",
    "              activation='tanh',\n",
    "              return_sequences=True)\n",
    "         )\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(GRU(4,\n",
    "              activation='tanh',\n",
    "              return_sequences=False)\n",
    "         )\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf82794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aactivation function \n",
    "\n",
    "# step = tf.Variable(0, trainable=False)\n",
    "# schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "#     [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# # lr and wd can be a function or a tensor\n",
    "# lr = 1e-3 * schedule(step)\n",
    "# wd = lambda: 1e-4 * schedule(step)\n",
    "\n",
    "# AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현실 고려 시 FN (음성으로 예측했는데 실제로 양성인 것 = 정상 (1) 으로 예측했는데 실제로 불량 (0) 인 것) 을 중점적으로 개선해야 한다. \n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adamax(), metrics=[tf.keras.metrics.AUC(curve='ROC')])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, min_delta = 0.003)\n",
    "filename = os.path.join(model_path, 'melting_tank_pretrained_model.h5')\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=2, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbdedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=64,\n",
    "                   validation_data=(x_valid, y_valid),\n",
    "                   callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_filename = 'mx_rscaler.pkl'\n",
    "joblib.dump(scaler, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c64c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c83b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred, columns=['TAG'])\n",
    "pred_df['TAG'] = pred_df['TAG'].apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 정상, 0 불량\n",
    "pred_df['TAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        # print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1 # print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91147735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속된 공정은 실제 불량을 정상으로 예측하는 FN 을 줄여야 함. 실제 정상을 불량으로 예측 시 설비를 정지시키는 수준이지만, 실제 불량을 정상 예측할 경우 다음 공정까지\n",
    "# 투입되는 모든 비용을 망치게 된다. 따라서 재현율 (recall) 중점으로 봐야 함. \n",
    "\n",
    "classify = confusion_matrix(test_label, pred_df)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(classify, classes=[0, 1], title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = precision_score(test_label, pred_df)\n",
    "print(\"precision: %0.4f\" %p)\n",
    "r = recall_score(test_label, pred_df)\n",
    "print(\"recall: %0.4f\" %r)\n",
    "f1 = f1_score(test_label, pred_df)\n",
    "print(\"f1-score: %0.4f\" %f1)\n",
    "acc = accuracy_score(test_label, pred_df)\n",
    "print(\"accuracy: %0.4f\" %acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12986604",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(test_label, pred_df)\n",
    "\n",
    "print(\"f1-score: %0.4f\" %f1)\n",
    "plt.plot([0, 1], [0, 0], linestyle='--')\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5c392",
   "metadata": {},
   "source": [
    "### realtime.py 파이썬 파일  \n",
    "1) mx_rscaler.pkl  \n",
    "2) melting_tank_stream.csv (다운로드한 제조 데이터셋 원본과 같음)  \n",
    "3) h5 pretrained model  \n",
    "\n",
    "을 이용해 구동함.  \n",
    "\n",
    "**결과는 PPT 자료의 캡처와 동영상 참조**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  \n",
    "import pandas as pd \n",
    "import streamlit as st \n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Dissolution Tank Condition\",\n",
    "    layout=\"wide\",\n",
    ")\n",
    "\n",
    "\n",
    "# Data Prepare\n",
    "FilePath = \"/home/kym/ML/input/kamp/대회 과제/Streamlit-main/melting_tank_stream.csv\"\n",
    "scaler_call = joblib.load(\"/home/kym/ML/input/kamp/대회 과제/Streamlit-main/mx_rscaler.pkl\") \n",
    "model_call = load_model('/home/kym/ML/input/kamp/대회 과제/Streamlit-main/melting_tank_pretrained_model.h5')\n",
    "\n",
    "@st.experimental_memo\n",
    "def get_data() -> pd.DataFrame:\n",
    "    return pd.read_csv(FilePath)\n",
    "\n",
    "df = get_data()\n",
    "df_Length = df.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dashboard title\n",
    "\n",
    "st.title(\"Dissolution Tank Condition\")\n",
    "\n",
    "\n",
    "\n",
    "placeholder_1 = st.empty()\n",
    "placeholder_2 = st.empty()\n",
    "# near real-time simulation\n",
    "Pie_Value = [0, 0]\n",
    "for seconds in range(df_Length):\n",
    "    \n",
    "    ndf = df.iloc[seconds:seconds+30]\n",
    "    result_mapping = {\n",
    "        \"OK\":1,\n",
    "        \"NG\":0\n",
    "    }\n",
    "    ndf.loc[:,\"TAG\"]=ndf.TAG.map(result_mapping)\n",
    "    \n",
    "    \n",
    "    \n",
    "    with placeholder_1.container():\n",
    "        Condition_Record, Condition_Est, Dummy_Area = st.columns((1,1,1))\n",
    "        with Condition_Record:\n",
    "            st.markdown(\"## Recorded TAG\")\n",
    "            Tag_Value=ndf[\"TAG\"][seconds+29]\n",
    "            if Tag_Value==1:\n",
    "                st.success(\"OK\")\n",
    "            else:\n",
    "                st.error(\"NG\")\n",
    "        with Condition_Est:\n",
    "            \n",
    "            st.markdown(\"## Estimated Condition\")\n",
    "            ndf.drop(['MELT_WEIGHT', 'TAG'], axis=1)\n",
    "            \n",
    "            new_x_df = pd.concat([ndf[\"MELT_TEMP\"][20:],ndf[\"MOTORSPEED\"][20:]] ,axis=1)\n",
    "            new_x_df_scale = scaler_call.transform(new_x_df)  \n",
    "            new_x_df_scale = new_x_df_scale.reshape(1,10,2)\n",
    "            Tag_Est = model_call.predict(new_x_df_scale) \n",
    "            \n",
    "            \n",
    "            if Tag_Est > 0.5595:\n",
    "                st.success(\"OK\")\n",
    "                Pie_Value[0] = Pie_Value[0] + 1\n",
    "            else:\n",
    "                st.error(\"NG\")\n",
    "                Pie_Value[1] = Pie_Value[1] + 1 \n",
    "            \n",
    "        \n",
    "    with placeholder_2.container():\n",
    "        \n",
    "        Tank_Graph, Fail_Ratio, Tank_Data = st.columns((2,1,1))\n",
    "        with Tank_Graph:\n",
    "            st.markdown(\"## Tank Condition\")\n",
    "            fig = make_subplots(rows=4, cols=1,\n",
    "                                subplot_titles=(\"Melting Temperature\", \"Motor Speed\", \"Melt Weight\", \"INSP\"))\n",
    "            fig.update_layout(margin=dict(l = 20,\n",
    "                                         r=20,\n",
    "                                         b=50,\n",
    "                                         t=20,\n",
    "                                         pad = 4))\n",
    "            fig.add_trace(go.Scatter(x=ndf.NUM, y=ndf.MELT_TEMP,\n",
    "                                        mode = \"lines\",\n",
    "                                        name = 'Temp.'),\n",
    "                                        row=1, col=1)\n",
    "            fig.add_trace(go.Scatter(x=ndf.NUM, y=ndf.MOTORSPEED,\n",
    "                                        mode = \"lines\",\n",
    "                                        name = 'Motor Speed'),\n",
    "                                        row=2, col=1)\n",
    "            fig.add_trace(go.Scatter(x=ndf.NUM, y=ndf.MELT_WEIGHT,\n",
    "                                        mode = \"lines\",\n",
    "                                        name = 'WEIGHT'),\n",
    "                                        row=3, col=1)\n",
    "            fig.add_trace(go.Scatter(x=ndf.NUM, y=ndf.INSP,\n",
    "                                        mode = \"lines\",\n",
    "                                        name = 'INSP'),\n",
    "                                        row=4, col=1)\n",
    "            \n",
    "            \n",
    "            fig.add_annotation(x=ndf.NUM[seconds+29], y=ndf.MELT_TEMP[seconds+29],\n",
    "                                text = 'CV',\n",
    "                                showarrow = True,\n",
    "                                arrowhead= 1,\n",
    "                                row=1, col=1)\n",
    "            fig.add_annotation(x=ndf.NUM[seconds+29], y=ndf.MOTORSPEED[seconds+29],\n",
    "                                text = 'CV',\n",
    "                                showarrow = True,\n",
    "                                arrowhead= 1,\n",
    "                                row=2, col=1)\n",
    "            fig.add_annotation(x=ndf.NUM[seconds+29], y=ndf.MELT_WEIGHT[seconds+29],\n",
    "                                text = 'CV',\n",
    "                                showarrow = True,\n",
    "                                arrowhead= 1,\n",
    "                                row=3, col=1)\n",
    "            fig.add_annotation(x=ndf.NUM[seconds+29], y=ndf.INSP[seconds+29],\n",
    "                                text = 'CV',\n",
    "                                showarrow = True,\n",
    "                                arrowhead= 1,\n",
    "                                row=4, col=1)\n",
    "            st.plotly_chart(fig, use_container_width= True)\n",
    "            \n",
    "        with Fail_Ratio:\n",
    "            st.markdown(\"## Estimated NG Ratio\")\n",
    "            labels = ['OK', 'NG']\n",
    "            \n",
    "            fig = go.Figure(data =[go.Pie(labels = labels, values= Pie_Value, hole=0.3)])\n",
    "            st.plotly_chart(fig, use_container_width= True)\n",
    "            \n",
    "                \n",
    "        with Tank_Data:\n",
    "            st.markdown(\"## Recorded Data View\")\n",
    "            view_NDF = ndf.drop(['STD_DT', 'NUM'], axis=1)\n",
    "            result_mapping = {\n",
    "                1: \"OK\",\n",
    "                0: \"NG\"\n",
    "                }\n",
    "            view_NDF.loc[:,\"TAG\"]=view_NDF.TAG.map(result_mapping)\n",
    "            st.dataframe(view_NDF[20:])\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
